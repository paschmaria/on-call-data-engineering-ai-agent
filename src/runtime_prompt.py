#!/usr/bin/env python3
"""
Runtime Prompt Template for DE-Agent

This module contains the prompt template used to interact with the LLM
for diagnostic analysis of Airflow failures.
"""

import json
from typing import Dict, Any, List


def format_diagnostic_data(diagnostics: Dict[str, Any]) -> str:
    """
    Format diagnostic data for inclusion in the prompt.
    
    Args:
        diagnostics: Raw diagnostic data from various sources
        
    Returns:
        str: Formatted diagnostic information
    """
    sections = []
    
    # Format MWAA logs
    if diagnostics.get('mwaa_logs'):
        sections.append(
            "**MWAA Task Logs:**\n```\n"
            f"{diagnostics['mwaa_logs'][:2000]}"  # Limit to prevent token overflow
            "\n```"
        )
    
    # Format DAG status
    if diagnostics.get('dag_status') and 'error' not in diagnostics['dag_status']:
        status = diagnostics['dag_status']
        summary = status.get('summary', {})
        sections.append(
            "**DAG Run Status:**\n"
            f"- Total tasks: {summary.get('total_tasks', 'Unknown')}\n"
            f"- Failed: {summary.get('failed', 0)}\n"
            f"- Success: {summary.get('success', 0)}\n"
            f"- Running: {summary.get('running', 0)}\n"
            f"- Upstream failed: {summary.get('upstream_failed', 0)}"
        )
    
    # Format Redshift audit logs
    if diagnostics.get('redshift_audit'):
        audit_logs = diagnostics['redshift_audit']
        if audit_logs and not any('error' in log for log in audit_logs):
            sections.append("**Redshift Audit Logs:**")
            for log in audit_logs[:3]:  # Limit to 3 most recent
                sections.append(
                    f"- {log.get('event_timestamp', 'Unknown time')}: "
                    f"{log.get('error_message', log.get('query_text', 'No details'))[:200]}"
                )
    
    # Format CloudWatch errors
    if diagnostics.get('cloudwatch_errors'):
        errors = diagnostics['cloudwatch_errors']
        if errors and isinstance(errors, list):
            sections.append("**CloudWatch Lambda Errors:**")
            for error in errors[:5]:  # Limit to 5 most recent
                sections.append(f"- {error[:200]}")
    
    # Note any diagnostic errors
    if diagnostics.get('errors'):
        sections.append(
            "**Diagnostic Collection Errors:**\n" +
            "\n".join(f"- {err}" for err in diagnostics['errors'])
        )
    
    return "\n\n".join(sections)


def get_diagnostic_prompt(context: Dict[str, Any]) -> str:
    """
    Generate the complete prompt for LLM diagnostic analysis.
    
    Args:
        context: Complete context including parsed data and diagnostics
        
    Returns:
        str: Formatted prompt for the LLM
    """
    # Extract key information
    dag_id = context.get('dag_id', 'Unknown')
    task_id = context.get('task_id', 'Unknown')
    exception = context.get('exception', 'Unknown error')
    error_type = context.get('error_type', 'unknown')
    execution_time = context.get('execution_time', 'Unknown')
    
    # Format diagnostic data
    diagnostic_info = format_diagnostic_data(context.get('diagnostics', {}))
    
    # Build the prompt
    prompt = f"""You are DE-Bot, an expert data engineering AI assistant specializing in diagnosing Apache Airflow failures. Your role is to analyze error logs, identify root causes, and provide actionable solutions.

## Current Failure Information

**DAG:** {dag_id}
**Task:** {task_id}
**Execution Time:** {execution_time}
**Error Type:** {error_type}
**Exception:** {exception}

## Diagnostic Data

{diagnostic_info}

## Your Task

Analyze the above information and provide a comprehensive diagnostic response following this EXACT format:

### üîç Root Cause Analysis

[Provide a clear, concise explanation of why this failure occurred. Be specific and reference the actual error messages and logs.]

### üìä Error Pattern

[Identify if this is a one-time issue or part of a pattern. Look for:
- Cascading failures from upstream tasks
- Repeated errors in audit logs
- Resource constraints or timeouts
- Connection/permission issues]

### üõ†Ô∏è Recommended Actions

1. **Immediate Fix**: [Specific steps to resolve the current failure]
2. **Prevention**: [Changes to prevent recurrence]
3. **Monitoring**: [What to watch for in the future]

### üí° Additional Context

[Any relevant insights about:
- Related system issues
- Best practices being violated
- Performance optimization opportunities
- Dependencies that might be affected]

### üìù Summary

**Severity**: [Critical/High/Medium/Low]
**Estimated Fix Time**: [X minutes/hours]
**Requires**: [What team/permissions needed]

---
*Generated by DE-Bot at {context.get('timestamp', 'Unknown')}*

## Guidelines for your response:

1. Be specific and actionable - avoid generic advice
2. Reference actual log messages and error codes
3. Prioritize quick fixes that can unblock the pipeline
4. Consider the time of day and urgency (late night failures might need simpler fixes)
5. If you see database/connection errors, always suggest checking connection pools and credentials
6. For timeout errors, analyze if the timeout is reasonable for the task
7. For DBT errors, focus on the specific model and its dependencies
8. Always maintain a helpful, professional tone

Now, provide your diagnostic analysis:"""
    
    return prompt


def get_fallback_response(error_type: str, dag_id: str, task_id: str) -> str:
    """
    Generate a fallback response when LLM is unavailable.
    
    Args:
        error_type: Type of error detected
        dag_id: DAG identifier
        task_id: Task identifier
        
    Returns:
        str: Fallback diagnostic message
    """
    base_response = f"""
ü§ñ **DE-Bot Diagnostic Report**

**DAG**: {dag_id}
**Task**: {task_id}
**Error Type**: {error_type}

‚ö†Ô∏è I'm currently unable to perform a full analysis, but here are some general troubleshooting steps:

"""
    
    error_specific_advice = {
        'timeout': """
### Timeout Error Detected

1. **Check task duration**: Review historical run times to see if this is unusual
2. **Increase timeout**: If the task legitimately needs more time, increase the timeout value
3. **Optimize query/process**: Look for inefficient queries or processes that could be optimized
4. **Check system load**: High system load can cause tasks to run slower than normal
""",
        'dbt_error': """
### DBT Model Error Detected

1. **Check model SQL**: Review the model definition for syntax errors
2. **Verify dependencies**: Ensure all upstream models have completed successfully
3. **Check data quality**: Look for unexpected nulls or data type mismatches
4. **Review recent changes**: Check if recent code changes affected this model
""",
        'connection': """
### Connection Error Detected

1. **Verify credentials**: Check that connection credentials haven't expired
2. **Test connectivity**: Manually test the connection from the Airflow environment
3. **Check firewall rules**: Ensure necessary ports are open
4. **Review connection pool**: Check if connection pool is exhausted
""",
        'permission': """
### Permission Error Detected

1. **Check IAM roles**: Verify the task has necessary AWS permissions
2. **Database permissions**: Ensure database user has required privileges
3. **File permissions**: Check file/directory permissions if accessing filesystem
4. **Credential rotation**: Verify credentials haven't been recently rotated
"""
    }
    
    specific_advice = error_specific_advice.get(
        error_type,
        "### General Troubleshooting\n\n"
        "1. Check the full task logs for more details\n"
        "2. Verify all connections and credentials\n"
        "3. Look for any recent infrastructure changes\n"
        "4. Check if this is affecting other similar tasks"
    )
    
    return base_response + specific_advice + "\n\n---\n*Fallback response - LLM unavailable*"


# Example usage and testing
if __name__ == "__main__":
    # Test context
    test_context = {
        'dag_id': 'test_analytics_pipeline',
        'task_id': 'run_dim_customers',
        'execution_time': '2024-01-15T03:00:00+00:00',
        'exception': 'CosmosDbtRunError: Database Error in model dim_customers',
        'error_type': 'dbt_error',
        'diagnostics': {
            'mwaa_logs': 'Sample log content here...',
            'dag_status': {
                'summary': {
                    'total_tasks': 10,
                    'failed': 3,
                    'success': 5,
                    'running': 2,
                    'upstream_failed': 0
                }
            },
            'redshift_audit': [
                {
                    'event_timestamp': '2024-01-15 03:15:22',
                    'error_message': 'Column customer_id does not exist'
                }
            ]
        },
        'timestamp': '2024-01-15T03:20:00Z'
    }
    
    # Generate prompt
    prompt = get_diagnostic_prompt(test_context)
    print("Generated Prompt Length:", len(prompt))
    print("\nFirst 500 characters:")
    print(prompt[:500])
    
    # Test fallback
    fallback = get_fallback_response('timeout', 'test_dag', 'test_task')
    print("\n\nFallback Response:")
    print(fallback)